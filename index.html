<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Enhancing Construction Site Safety: Advanced Deep Learning Approaches for Accurate Helmet Detection</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Enhancing Construction Site Safety: Advanced Deep Learning Approaches for Accurate Helmet Detection</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="LINK TO LEFKI IOANNA PANAGIOTOU'S PROFILE" target="_blank">Lefki Ioanna Panagiotou</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="LINK TO ZACHARIAS IOSIF SIFAKIS' PROFILE" target="_blank">Zacharias Iosif Sifakis</a><sup>*</sup></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Wisconsin - Madison<br>ECE766 - Final Project (Spring 2024)</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                    </div>

                  

                   

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- Google slides Link -->
                <span class="link-block">
                  <a href="https://docs.google.com/presentation/d/10eYvg_7GoZW7Hcm6mV9vxDlIlwcodQM2UQ8ESOhssMg/edit?usp=sharing" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Image before Abstract -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/intro_img.png" alt="Descriptive Alt Text" style="width:100%; height:auto;">
      <h2 class="subtitle has-text-centered">
        Sample images from dataset.
      </h2>
    </div>
  </div>
</section>
<!-- End Image before Abstract -->

<!-- Introduction and Motivation -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction and Motivation</h2>
        <div class="content has-text-justified">
          <p>
            The construction industry is known for its high-risk environments, with workers exposed to various hazards, including falling objects, which can lead to severe head injuries or even fatalities. The critical nature of these accidents, particularly head injuries resulting from the improper use of safety helmets, underscores a pressing concern for worker safety. In 2012 alone, the construction sector witnessed over 65,000 head injuries requiring days away from work, with head injuries culminating in 1,020 fatalities, according to the 2015 edition of the National Safety Council's "Injury Facts" chartbook <a href="#ref-6">[6]</a>. Moreover, out of the total of 391 people with body parts injured in the construction industry in 2016, 161 people (41.2%) were injured in the head, according to the Korea Occupational Safety and Health Agency <a href="#ref-9">[9]</a>.
          </p>
          <p>
            In response to this alarming issue, this project aims to find the best automatic safety helmet detection system that will mitigate workplace accidents, by leveraging the advanced capabilities of deep learning models in object detection. Many architectures can be used to solve this object detection problem. In this research, we will investigate various state-of-the-art models, including YOLOv5 <a href="#ref-7">[7]</a>, YOLOv8 <a href="#ref-8">[8]</a>, Faster-RCNN <a href="#ref-11">[11]</a>, and Vision Transformers (ViT) <a href="#ref-3">[3]</a>, to ascertain their applicability and effectiveness on our dataset.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Introduction and Motivation -->

<!-- Dataset Description Section -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset Description</h2>
        <div class="content">
          <p>
            The dataset we used for this project is the Hard Hat worker image dataset published by MakeML <a href="#ref-5">[5]</a>. This dataset is specifically designed for the detection of hard helmets used in the construction industry. It contains 5000 images, each accompanied by bounding box annotation files. Initially, the dataset includes three classes: Helmet, Person, and Head with more than 26000 total instances. 
          </p>
          <figure>
            <img src="static/images/data_description.jpg" alt="Histogram of the three classes in the dataset">
            <figcaption>Figure 1: Histogram of the three classes in dataset.</figcaption>
          </figure>
          <h3 class="title is-4">Data Pre-processing</h3>
          <p>
            As we can observe from the Figure 1 above, the dataset is highly imbalanced. Most of the instances (approximately 15000) refer to the 'helmet' class while only about 5000 instances are of the 'head' class and less than 1000 instances are of the 'person' class. So, for this research, we will focus only on two classes: 'Helmet' and 'Head'. The decision to focus only on these two classes is also based on the project’s primary goal of detecting whether workers are wearing their safety helmets correctly. By identifying instances of "Head" without a corresponding "Helmet," the system can alert supervisors to potential safety violations, allowing for prompt corrective action. Furthermore, we reshaped the images into (640x640) to comply with the YOLO input size requirements. Finally, we split our data into 3 sets (training, validation, and test sets) with 3000, 1000, and 1000 images respectively.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Dataset Description Section -->


  
<!-- Method Section -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content">
          <p>
            For this project, we trained the YOLOv5 and YOLOv8 models. These are state-of-the-art object detection architectures that have gained significant popularity due to their efficiency and accuracy. These architectures share several key components that contribute to their exceptional performance:
          </p>
          <ol>
            <li>
              <strong>Backbone:</strong> Both YOLOv5 and YOLOv8 employ a modified version of the CSPNet (Cross Stage Partial Network) as their backbone for feature extraction. This design choice helps reduce the model's complexity while maintaining its effectiveness in capturing essential features from the input images.
            </li>
            <li>
              <strong>Neck:</strong> The PANet (Path Aggregation Network) serves as the neck in these architectures. Its primary function is to aggregate feature maps from different scales, enabling the model to detect objects of various sizes more effectively. The neck plays a crucial role in enhancing the model's ability to handle scale variations.
            </li>
            <li>
              <strong>Head:</strong> The detection head is responsible for predicting bounding boxes, objectness scores, and class probabilities. In YOLOv5, anchor boxes are utilized to improve detection accuracy. However, YOLOv8 adopts an anchor-free split Ultralytics head, which contributes to better accuracy and a more efficient detection process compared to anchor-based approaches.
            </li>
            <li>
              <strong>Scalability:</strong> Both versions of YOLO offers multiple model sizes (nano, small, medium, large, extra large) according to the number of parameters, allowing users to choose a model that best suits their specific requirements in terms of speed and accuracy. This scalability makes YOLO adaptable to various application domains and computational constraints.
            </li>
          </ol>
          <p>
            Here, we focus on the YOLOv5n and YOLOv8n variants due to limited computation resources. Adam optimizer was utilized for training the networks using a learning rate of 0.001 and momentum of 0.937 with batch size of 32.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Method Section -->
















<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!-- References Section -->
<section class="section" id="References">
  <div class="container is-max-desktop content">
    <h2 class="title">References</h2>
    <ol>
      <li id="ref-1">Santiago Barro-Torres et al. “Real-time personal protective equipment monitoring system”. In: Computer Communications 36.1 (2012), pp. 42–50. DOI: <a href="https://doi.org/10.1016/j.comcom.2012.01.005">10.1016/j.comcom.2012.01.005</a>. URL: <a href="https://www.sciencedirect.com/science/article/pii/S0140366412000060">https://www.sciencedirect.com/science/article/pii/S0140366412000060</a>.</li>
      <li id="ref-2">Nicolas Carion et al. “End-to-end object detection with transformers”. In: European conference on computer vision. Springer. 2020, pp. 213–229.</li>
      <li id="ref-3">Alexey Dosovitskiy et al. “An image is worth 16x16 words: Transformers for image recognition at scale”. In: arXiv preprint arXiv:2010.11929 (2020).</li>
      <li id="ref-4">Pathasu Doungmala and Katanyoo Klubsuwan. “Helmet Wearing Detection in Thailand Using Haar Like Feature and Circle Hough Transform on Image Processing”. In: 2016 IEEE International Conference on Computer and Information Technology (CIT). 2016, pp. 611–614. DOI: 10.1109/CIT.2016.87.</li>
      <li id="ref-5">Hard Hat Dataset. Make ML. URL: <a href="https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection/data">https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection/data</a>.</li>
      <li id="ref-6">HexArmor. “The hard truth about safety helmet injuries and statistics”. In: (2019). URL: <a href="https://www.hexarmor.com/posts/the-hard-truth-about-safety-helmet-injuries-and-statistics">https://www.hexarmor.com/posts/the-hard-truth-about-safety-helmet-injuries-and-statistics</a>.</li>
      <li id="ref-7">Glenn Jocher. Ultralytics YOLOv5. Version 7.0. 2020. DOI: 10.5281/zenodo.3908559. URL: <a href="https://github.com/ultralytics/yolov5">https://github.com/ultralytics/yolov5</a>.</li>
      <li id="ref-8">Glenn Jocher, Ayush Chaurasia, and Jing Qiu. Ultralytics YOLOv8. Version 8.0.0. 2023. URL: <a href="https://github.com/ultralytics/ultralytics">https://github.com/ultralytics/ultralytics</a>.</li>
      <li id="ref-9">Sung Hun Kim et al. “Safety helmet wearing management system for construction workers using three-axis accelerometer sensor”. In: Applied Sciences 8.12 (2018), p. 2400.</li>
      <li id="ref-10">Tsung-Yi Lin et al. “Microsoft coco: Common objects in context”. In: Computer Vision–ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13. Springer. 2014, pp. 740–755.</li>
      <li id="ref-11">Shaoqing Ren et al. “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks”. In: Advances in Neural Information Processing Systems. Ed. by C. Cortes et al. Vol. 28. Curran Associates, Inc., 2015. URL: <a href="https://proceedings.neurips.cc/paper_files/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf</a>.</li>
      <li id="ref-12">Abu H. M. Rubaiyat et al. “Automatic Detection of Helmet Uses for Construction Safety”. In: 2016 IEEE/WIC/ACM International Conference on Web Intelligence Workshops (WIW). 2016, pp. 135–142. DOI: 10.1109/WIW.2016.045.</li>
      <li id="ref-13">Zijian Wang et al. “Fast personal protective equipment detection for real construction sites using deep learning approaches”. In: Sensors 21.10 (2021), p. 3478.</li>
    </ol>
  </div>
</section>
<!-- End References Section -->



  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
